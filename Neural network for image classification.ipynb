{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using materials from course MTAT.03.227 Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\rasmusm\\AppData\\Local\\Continuum\\anaconda3\\envs\\neurovorgud\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rasmusm\\AppData\\Local\\Continuum\\anaconda3\\envs\\neurovorgud\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rasmusm\\AppData\\Local\\Continuum\\anaconda3\\envs\\neurovorgud\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rasmusm\\AppData\\Local\\Continuum\\anaconda3\\envs\\neurovorgud\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rasmusm\\AppData\\Local\\Continuum\\anaconda3\\envs\\neurovorgud\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rasmusm\\AppData\\Local\\Continuum\\anaconda3\\envs\\neurovorgud\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = io.loadmat('6845348/images_natimg2800_all.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = mt['imgs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divided into 11 classes\n",
    "classes = io.loadmat('stringer-pachitariu-et-al-2018b/classes/stimuli_class_assignment_confident.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for i in range(2800):\n",
    "    train.append(imgs[:,:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.asarray(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(classes['class_assignment'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, y_train, test_size=0.12, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 2, 2], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes['class_assignment'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  6, ...,  2,  0, 11], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = X_train.mean(axis=(0,1,2))\n",
    "std = X_train.std(axis=(0,1,2))\n",
    "X_train_norm = (X_train - mu)/std\n",
    "X_test_norm = (X_test - mu)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Activation, Flatten, Dense, MaxPooling2D, BatchNormalization, Dropout, Reshape\n",
    "\n",
    "x = Input(shape=(68, 270))\n",
    "rs = Reshape((68, 270, 1))(x)\n",
    "c1 = Conv2D(32, (3, 3), strides=(1, 1), padding=\"same\")(rs)\n",
    "b1 = BatchNormalization()(c1)\n",
    "a1 = Activation('relu')(b1)\n",
    "c2 = Conv2D(32, (3, 3), strides=(1, 1), padding=\"valid\")(a1)\n",
    "b2 = BatchNormalization()(c2)\n",
    "a2 = Activation('relu')(b2)\n",
    "p2 = MaxPooling2D(pool_size=2)(a2)\n",
    "d2 = Dropout(rate=0.25)(p2)\n",
    "f2 = Flatten()(d2)\n",
    "h3 = Dense(100)(f2)\n",
    "b3 = BatchNormalization()(h3)\n",
    "a3 = Activation('relu')(b3)\n",
    "d3 = Dropout(rate=0.5)(a3)\n",
    "z = Dense(12)(d3)\n",
    "p = Activation('softmax')(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 68, 270)           0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 68, 270, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 68, 270, 32)       320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 68, 270, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 68, 270, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 66, 268, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 66, 268, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 66, 268, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 33, 134, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 33, 134, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 141504)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               14150500  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 12)                1212      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 14,161,936\n",
      "Trainable params: 14,161,608\n",
      "Non-trainable params: 328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Model(inputs=x, outputs=p)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2365 samples, validate on 99 samples\n",
      "Epoch 1/5\n",
      "2365/2365 [==============================] - 526s 222ms/step - loss: 2.7235 - accuracy: 0.1712 - val_loss: 2.6869 - val_accuracy: 0.1414\n",
      "Epoch 2/5\n",
      "2365/2365 [==============================] - 523s 221ms/step - loss: 1.7010 - accuracy: 0.4406 - val_loss: 2.5925 - val_accuracy: 0.0909\n",
      "Epoch 3/5\n",
      "2365/2365 [==============================] - 521s 220ms/step - loss: 1.0699 - accuracy: 0.6778 - val_loss: 2.8252 - val_accuracy: 0.1212\n",
      "Epoch 4/5\n",
      "2365/2365 [==============================] - 524s 222ms/step - loss: 0.6135 - accuracy: 0.8715 - val_loss: 2.5897 - val_accuracy: 0.1212\n",
      "Epoch 5/5\n",
      "2365/2365 [==============================] - 526s 223ms/step - loss: 0.4111 - accuracy: 0.9345 - val_loss: 2.4794 - val_accuracy: 0.1111\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_norm, y_train, batch_size=64, epochs=5, validation_split=0.04)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336/336 [==============================] - 19s 56ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4774220898037864, 0.1369047611951828]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_norm, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2464/2464 [==============================] - 134s 55ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4992056171615402, 0.6160714030265808]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train_norm, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
